---
layout: single
title: "Professional Experience"
permalink: /experience/
redirect_from:
  - /experience
classes: wide
author_profile: true 
---

There is no doubt that each internship and research opportunity has brought me different aspects of harvest and growth.
I would like to thank all the professors, Ph.D./MPhil candidates, mentors, and colleagues for their generous help and guidance.

# INTERNSHIPS

### **Covariant(Shenzhen)** 
*Machine Learning Engineer Intern in Shenzhen, China* <br>
May. 2022 - Jul. 2022 \| Mentor: [Yide Shentu](https://www.linkedin.com/in/yide-shentu-9590a2ab/)

* Implemented relevant structures and classes with the Mechanical team to make a new type of small USB wrist camera compatible with the company-wise video recording & data collection pipeline.
* Wrote scripts to let the robot gradually gain speed in the picking cycle for the same object until it falls, which automated the long-tail data collection process, and ran smoothy for more than 20 hours.
* Constructed a self-supervised video segmentation pipeline with 3D vision and rendering techniques to predict the picking object silhouettes, which could help to detect robot picking failures in third-person view.

### **Hikvision Digital Technology** 
*Software Engineer Intern in Hangzhou, China* <br>
Jun. 2020 - Aug. 2020 \| Mentor: Yishi Deng

* Processed and analyzed thousands of lines of Excel & Html records of Project Subunit information and organized them into the dataset.

# RESEARCH PROJECTS

### **Online Easy Example Mining for Weakly-supervised Gland Segmentation from Histology Images**
*Undergraduate Research Assistant in HKUST, Hong Kong* <br>
Sep. 2021 - June. 2022 | Supervisor: [Prof. Xiaomeng Li](https://xmengli.github.io/) <br>
MICCAI 2022 Accepted [Paper](https://arxiv.org/pdf/2206.06665.pdf)

* Analyzed and pointed out that the key problem of gland segmentation is the confusion caused by the morphological homogeneity of histology images, rather than the local activation problem that most WSSS methods faced.
* Proposed the Online Easy Example Mining (OEEM) technique to mine the credible supervision signals in pseudo-mask, mitigating the damage of confused supervisions for gland segmentation. 
* Designed a strong two-stage framework for gland segmentation. Our fully-supervised and proposed weakly-supervised OEEM strategy achieved State-of-the-arts results for gland segmentation on the GlaS dataset.

### **Exploring the Effects of Self-Mockery to Improve Task-oriented Chatbot’s Social Intelligence**
*Undergraduate Research Assistant in HKUST, Hong Kong* <br>
Jan. – Sep. 2021 | Supervisor: [Prof. Xiaojuan Ma](https://www.cse.ust.hk/~mxj/) <br>
DIS 2022 Accepted [Paper](https://dl.acm.org/doi/abs/10.1145/3532106.3533461) [Appears in Acknowledgement]

* Proposed a template-based self-mockery generation method, which could construct four related components in the dialogue context and fit in the pre-defined template for real-time human-robot interaction.
* Built the Self-mockery Robot and deployed on the web for subsequent User Study.
* Studied the processing methods and dialogue of robots on several online shopping platforms and designed the baseline chatbot language without self-mockery function as the control group for the comparative experiment.
* Participated in quantitative results analysis and verified the effectiveness of self-mockery in improving Chatbot’s Social Intelligence.

### **Lung Tumor Segmentation and Drug Resistance Prediction Through Novel Deep Learning Architectures** 
*Undergraduate Research Assistant in HKUST, Hong Kong* <br>
Jun. – Aug. 2021 | Supervisor: [Prof. Xiaomeng Li](https://xmengli.github.io/)

* Cropped out the lung part and eliminated background noise of the given 3D CT lung images from Queen Mary Hospital, Hong Kong.
* Utilizing Multi-Modality learning method with the nnUNet to train the segmentation model.
* Appended a classification branch at the lowest level of the segmentation network for the Drug Resistance Level prediction, iteratively frozen and trained the two branches, and get over 70% accuracy.